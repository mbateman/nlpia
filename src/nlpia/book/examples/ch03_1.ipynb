{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'faster',\n",
       " 'harry',\n",
       " 'got',\n",
       " 'to',\n",
       " 'the',\n",
       " 'store',\n",
       " ',',\n",
       " 'the',\n",
       " 'faster',\n",
       " 'harry',\n",
       " ',',\n",
       " 'the',\n",
       " 'faster',\n",
       " ',',\n",
       " 'would',\n",
       " 'get',\n",
       " 'home',\n",
       " '.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "sentence = \"The faster Harry got to the store, the faster Harry, the faster, would get home.\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(sentence.lower())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 4,\n",
       "         'faster': 3,\n",
       "         'harry': 2,\n",
       "         'got': 1,\n",
       "         'to': 1,\n",
       "         'store': 1,\n",
       "         ',': 3,\n",
       "         'would': 1,\n",
       "         'get': 1,\n",
       "         'home': 1,\n",
       "         '.': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "bag_of_words = Counter(tokens)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4),\n",
       " ('faster', 3),\n",
       " (',', 3),\n",
       " ('harry', 2),\n",
       " ('got', 1),\n",
       " ('to', 1),\n",
       " ('store', 1),\n",
       " ('would', 1),\n",
       " ('get', 1),\n",
       " ('home', 1),\n",
       " ('.', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1818"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_harry_appears = bag_of_words['harry']\n",
    "num_unique_words = len(bag_of_words)\n",
    "tf = times_harry_appears / num_unique_words\n",
    "round(tf, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 20,\n",
       "         'kite': 16,\n",
       "         'is': 7,\n",
       "         'traditionally': 1,\n",
       "         'tethered': 2,\n",
       "         'heavier-than-air': 1,\n",
       "         'craft': 2,\n",
       "         'with': 2,\n",
       "         'wing': 5,\n",
       "         'surfaces': 1,\n",
       "         'that': 2,\n",
       "         'react': 1,\n",
       "         'against': 1,\n",
       "         'the': 26,\n",
       "         'air': 2,\n",
       "         'to': 5,\n",
       "         'create': 1,\n",
       "         'lift': 4,\n",
       "         'and': 10,\n",
       "         'drag.': 1,\n",
       "         'consists': 2,\n",
       "         'of': 10,\n",
       "         'wings': 1,\n",
       "         ',': 15,\n",
       "         'tethers': 2,\n",
       "         'anchors.': 2,\n",
       "         'kites': 8,\n",
       "         'often': 2,\n",
       "         'have': 4,\n",
       "         'bridle': 2,\n",
       "         'guide': 1,\n",
       "         'face': 1,\n",
       "         'at': 3,\n",
       "         'correct': 1,\n",
       "         'angle': 1,\n",
       "         'so': 3,\n",
       "         'wind': 2,\n",
       "         'can': 3,\n",
       "         'it.': 1,\n",
       "         \"'s\": 2,\n",
       "         'also': 3,\n",
       "         'may': 4,\n",
       "         'be': 5,\n",
       "         'designed': 2,\n",
       "         'not': 1,\n",
       "         'needed': 1,\n",
       "         ';': 2,\n",
       "         'when': 2,\n",
       "         'kiting': 3,\n",
       "         'sailplane': 1,\n",
       "         'for': 2,\n",
       "         'launch': 1,\n",
       "         'tether': 1,\n",
       "         'meets': 1,\n",
       "         'single': 1,\n",
       "         'point.': 1,\n",
       "         'fixed': 1,\n",
       "         'or': 6,\n",
       "         'moving': 2,\n",
       "         'untraditionally': 1,\n",
       "         'in': 7,\n",
       "         'technical': 2,\n",
       "         'tether-set-coupled': 1,\n",
       "         'sets': 1,\n",
       "         'even': 2,\n",
       "         'though': 1,\n",
       "         'system': 1,\n",
       "         'still': 1,\n",
       "         'called': 2,\n",
       "         'kite.': 1,\n",
       "         'sustains': 1,\n",
       "         'flight': 1,\n",
       "         'generated': 1,\n",
       "         'flows': 1,\n",
       "         'around': 1,\n",
       "         'surface': 2,\n",
       "         'producing': 1,\n",
       "         'low': 1,\n",
       "         'pressure': 2,\n",
       "         'above': 1,\n",
       "         'high': 1,\n",
       "         'below': 1,\n",
       "         'wings.': 1,\n",
       "         'interaction': 1,\n",
       "         'generates': 1,\n",
       "         'horizontal': 1,\n",
       "         'drag': 2,\n",
       "         'along': 1,\n",
       "         'direction': 1,\n",
       "         'wind.': 1,\n",
       "         'resultant': 1,\n",
       "         'force': 2,\n",
       "         'vector': 1,\n",
       "         'from': 1,\n",
       "         'components': 1,\n",
       "         'opposed': 1,\n",
       "         'by': 2,\n",
       "         'tension': 1,\n",
       "         'one': 1,\n",
       "         'more': 1,\n",
       "         'lines': 1,\n",
       "         'which': 2,\n",
       "         'attached.': 1,\n",
       "         'anchor': 1,\n",
       "         'point': 1,\n",
       "         'line': 1,\n",
       "         'static': 1,\n",
       "         '(': 1,\n",
       "         'e.g.': 1,\n",
       "         'towing': 1,\n",
       "         'running': 1,\n",
       "         'person': 1,\n",
       "         'boat': 1,\n",
       "         'free-falling': 1,\n",
       "         'anchors': 1,\n",
       "         'as': 5,\n",
       "         'paragliders': 1,\n",
       "         'fugitive': 1,\n",
       "         'parakites': 1,\n",
       "         'vehicle': 1,\n",
       "         ')': 1,\n",
       "         '.': 2,\n",
       "         'same': 1,\n",
       "         'principles': 1,\n",
       "         'fluid': 1,\n",
       "         'flow': 1,\n",
       "         'apply': 1,\n",
       "         'liquids': 1,\n",
       "         'are': 3,\n",
       "         'used': 2,\n",
       "         'under': 1,\n",
       "         'water.': 1,\n",
       "         'hybrid': 1,\n",
       "         'comprising': 1,\n",
       "         'both': 1,\n",
       "         'lighter-than-air': 1,\n",
       "         'balloon': 1,\n",
       "         'well': 1,\n",
       "         'lifting': 1,\n",
       "         'kytoon.': 1,\n",
       "         'long': 1,\n",
       "         'varied': 1,\n",
       "         'history': 1,\n",
       "         'many': 1,\n",
       "         'different': 1,\n",
       "         'types': 1,\n",
       "         'flown': 3,\n",
       "         'individually': 1,\n",
       "         'festivals': 1,\n",
       "         'worldwide.': 1,\n",
       "         'recreation': 1,\n",
       "         'art': 1,\n",
       "         'other': 1,\n",
       "         'practical': 1,\n",
       "         'uses.': 1,\n",
       "         'sport': 1,\n",
       "         'aerial': 1,\n",
       "         'ballet': 1,\n",
       "         'sometimes': 1,\n",
       "         'part': 1,\n",
       "         'competition.': 1,\n",
       "         'power': 2,\n",
       "         'multi-line': 1,\n",
       "         'steerable': 1,\n",
       "         'generate': 1,\n",
       "         'large': 1,\n",
       "         'forces': 1,\n",
       "         'activities': 1,\n",
       "         'such': 1,\n",
       "         'surfing': 1,\n",
       "         'landboarding': 1,\n",
       "         'fishing': 1,\n",
       "         'buggying': 1,\n",
       "         'new': 1,\n",
       "         'trend': 1,\n",
       "         'snow': 1,\n",
       "         'kiting.': 1,\n",
       "         'man-lifting': 1,\n",
       "         'been': 1,\n",
       "         'made': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "file = open('data/kite_text.txt', 'r')\n",
    "kite_text = file.read()\n",
    "file.close()\n",
    "tokens = tokenizer.tokenize(kite_text.lower())\n",
    "token_counts = Counter(tokens)\n",
    "token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kite', 16),\n",
       " (',', 15),\n",
       " ('kites', 8),\n",
       " ('wing', 5),\n",
       " ('lift', 4),\n",
       " ('may', 4),\n",
       " ('also', 3),\n",
       " ('kiting', 3),\n",
       " ('flown', 3),\n",
       " ('tethered', 2),\n",
       " ('craft', 2),\n",
       " ('air', 2),\n",
       " ('consists', 2),\n",
       " ('tethers', 2),\n",
       " ('anchors.', 2),\n",
       " ('often', 2),\n",
       " ('bridle', 2),\n",
       " ('wind', 2),\n",
       " (\"'s\", 2),\n",
       " ('designed', 2),\n",
       " (';', 2),\n",
       " ('moving', 2),\n",
       " ('technical', 2),\n",
       " ('even', 2),\n",
       " ('called', 2),\n",
       " ('surface', 2),\n",
       " ('pressure', 2),\n",
       " ('drag', 2),\n",
       " ('force', 2),\n",
       " ('.', 2),\n",
       " ('used', 2),\n",
       " ('power', 2),\n",
       " ('traditionally', 1),\n",
       " ('heavier-than-air', 1),\n",
       " ('surfaces', 1),\n",
       " ('react', 1),\n",
       " ('create', 1),\n",
       " ('drag.', 1),\n",
       " ('wings', 1),\n",
       " ('guide', 1),\n",
       " ('face', 1),\n",
       " ('correct', 1),\n",
       " ('angle', 1),\n",
       " ('it.', 1),\n",
       " ('needed', 1),\n",
       " ('sailplane', 1),\n",
       " ('launch', 1),\n",
       " ('tether', 1),\n",
       " ('meets', 1),\n",
       " ('single', 1),\n",
       " ('point.', 1),\n",
       " ('fixed', 1),\n",
       " ('untraditionally', 1),\n",
       " ('tether-set-coupled', 1),\n",
       " ('sets', 1),\n",
       " ('though', 1),\n",
       " ('system', 1),\n",
       " ('still', 1),\n",
       " ('kite.', 1),\n",
       " ('sustains', 1),\n",
       " ('flight', 1),\n",
       " ('generated', 1),\n",
       " ('flows', 1),\n",
       " ('around', 1),\n",
       " ('producing', 1),\n",
       " ('low', 1),\n",
       " ('high', 1),\n",
       " ('wings.', 1),\n",
       " ('interaction', 1),\n",
       " ('generates', 1),\n",
       " ('horizontal', 1),\n",
       " ('along', 1),\n",
       " ('direction', 1),\n",
       " ('wind.', 1),\n",
       " ('resultant', 1),\n",
       " ('vector', 1),\n",
       " ('components', 1),\n",
       " ('opposed', 1),\n",
       " ('tension', 1),\n",
       " ('one', 1),\n",
       " ('lines', 1),\n",
       " ('attached.', 1),\n",
       " ('anchor', 1),\n",
       " ('point', 1),\n",
       " ('line', 1),\n",
       " ('static', 1),\n",
       " ('(', 1),\n",
       " ('e.g.', 1),\n",
       " ('towing', 1),\n",
       " ('running', 1),\n",
       " ('person', 1),\n",
       " ('boat', 1),\n",
       " ('free-falling', 1),\n",
       " ('anchors', 1),\n",
       " ('paragliders', 1),\n",
       " ('fugitive', 1),\n",
       " ('parakites', 1),\n",
       " ('vehicle', 1),\n",
       " (')', 1),\n",
       " ('principles', 1),\n",
       " ('fluid', 1),\n",
       " ('flow', 1),\n",
       " ('apply', 1),\n",
       " ('liquids', 1),\n",
       " ('water.', 1),\n",
       " ('hybrid', 1),\n",
       " ('comprising', 1),\n",
       " ('lighter-than-air', 1),\n",
       " ('balloon', 1),\n",
       " ('well', 1),\n",
       " ('lifting', 1),\n",
       " ('kytoon.', 1),\n",
       " ('long', 1),\n",
       " ('varied', 1),\n",
       " ('history', 1),\n",
       " ('many', 1),\n",
       " ('different', 1),\n",
       " ('types', 1),\n",
       " ('individually', 1),\n",
       " ('festivals', 1),\n",
       " ('worldwide.', 1),\n",
       " ('recreation', 1),\n",
       " ('art', 1),\n",
       " ('practical', 1),\n",
       " ('uses.', 1),\n",
       " ('sport', 1),\n",
       " ('aerial', 1),\n",
       " ('ballet', 1),\n",
       " ('sometimes', 1),\n",
       " ('part', 1),\n",
       " ('competition.', 1),\n",
       " ('multi-line', 1),\n",
       " ('steerable', 1),\n",
       " ('generate', 1),\n",
       " ('large', 1),\n",
       " ('forces', 1),\n",
       " ('activities', 1),\n",
       " ('surfing', 1),\n",
       " ('landboarding', 1),\n",
       " ('fishing', 1),\n",
       " ('buggying', 1),\n",
       " ('new', 1),\n",
       " ('trend', 1),\n",
       " ('snow', 1),\n",
       " ('kiting.', 1),\n",
       " ('man-lifting', 1),\n",
       " ('made', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "tokens = [x for x in tokens if x not in stopwords]\n",
    "kite_count = Counter(tokens)\n",
    "kite_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07207207207207207,\n",
       " 0.06756756756756757,\n",
       " 0.036036036036036036,\n",
       " 0.02252252252252252,\n",
       " 0.018018018018018018,\n",
       " 0.018018018018018018,\n",
       " 0.013513513513513514,\n",
       " 0.013513513513513514,\n",
       " 0.013513513513513514,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.009009009009009009,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045,\n",
       " 0.0045045045045045045]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vector = []\n",
    "doc_length = len(tokens)\n",
    "for key, value in kite_count.most_common():\n",
    "    document_vector.append(value / doc_length)\n",
    "document_vector[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"The faster Harry got to the store, the faster and faster Harry would get home.\"]\n",
    "docs = docs + [\"Harry is hairy and faster than Jill.\"]\n",
    "docs = docs + [\"Jill is not as hairy as Harry.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "33\n",
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " 'and',\n",
       " 'as',\n",
       " 'faster',\n",
       " 'get',\n",
       " 'got',\n",
       " 'hairy',\n",
       " 'harry',\n",
       " 'home',\n",
       " 'is',\n",
       " 'jill',\n",
       " 'not',\n",
       " 'store',\n",
       " 'than',\n",
       " 'the',\n",
       " 'to',\n",
       " 'would']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_tokens = []\n",
    "for doc in docs:\n",
    "    doc_tokens += [sorted(tokenizer.tokenize(doc.lower()))]\n",
    "print(len(doc_tokens[0]))\n",
    "all_doc_tokens = sum(doc_tokens, [])\n",
    "print(len(all_doc_tokens))\n",
    "lexicon = sorted(set(all_doc_tokens))\n",
    "print(len(lexicon))\n",
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(',', 0),\n",
       "             ('.', 0),\n",
       "             ('and', 0),\n",
       "             ('as', 0),\n",
       "             ('faster', 0),\n",
       "             ('get', 0),\n",
       "             ('got', 0),\n",
       "             ('hairy', 0),\n",
       "             ('harry', 0),\n",
       "             ('home', 0),\n",
       "             ('is', 0),\n",
       "             ('jill', 0),\n",
       "             ('not', 0),\n",
       "             ('store', 0),\n",
       "             ('than', 0),\n",
       "             ('the', 0),\n",
       "             ('to', 0),\n",
       "             ('would', 0)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "zero_vector = OrderedDict((token, 0) for token in lexicon)\n",
    "zero_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([(',', 0.05555555555555555),\n",
       "              ('.', 0.05555555555555555),\n",
       "              ('and', 0.05555555555555555),\n",
       "              ('as', 0),\n",
       "              ('faster', 0.16666666666666666),\n",
       "              ('get', 0.05555555555555555),\n",
       "              ('got', 0.05555555555555555),\n",
       "              ('hairy', 0),\n",
       "              ('harry', 0.1111111111111111),\n",
       "              ('home', 0.05555555555555555),\n",
       "              ('is', 0),\n",
       "              ('jill', 0),\n",
       "              ('not', 0),\n",
       "              ('store', 0.05555555555555555),\n",
       "              ('than', 0),\n",
       "              ('the', 0.16666666666666666),\n",
       "              ('to', 0.05555555555555555),\n",
       "              ('would', 0.05555555555555555)]),\n",
       " OrderedDict([(',', 0),\n",
       "              ('.', 0.05555555555555555),\n",
       "              ('and', 0.05555555555555555),\n",
       "              ('as', 0),\n",
       "              ('faster', 0.05555555555555555),\n",
       "              ('get', 0),\n",
       "              ('got', 0),\n",
       "              ('hairy', 0.05555555555555555),\n",
       "              ('harry', 0.05555555555555555),\n",
       "              ('home', 0),\n",
       "              ('is', 0.05555555555555555),\n",
       "              ('jill', 0.05555555555555555),\n",
       "              ('not', 0),\n",
       "              ('store', 0),\n",
       "              ('than', 0.05555555555555555),\n",
       "              ('the', 0),\n",
       "              ('to', 0),\n",
       "              ('would', 0)]),\n",
       " OrderedDict([(',', 0),\n",
       "              ('.', 0.05555555555555555),\n",
       "              ('and', 0),\n",
       "              ('as', 0.1111111111111111),\n",
       "              ('faster', 0),\n",
       "              ('get', 0),\n",
       "              ('got', 0),\n",
       "              ('hairy', 0.05555555555555555),\n",
       "              ('harry', 0.05555555555555555),\n",
       "              ('home', 0),\n",
       "              ('is', 0.05555555555555555),\n",
       "              ('jill', 0.05555555555555555),\n",
       "              ('not', 0.05555555555555555),\n",
       "              ('store', 0),\n",
       "              ('than', 0),\n",
       "              ('the', 0),\n",
       "              ('to', 0),\n",
       "              ('would', 0)])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "doc_vectors = []\n",
    "for doc in docs:\n",
    "    vec = copy.copy(zero_vector)\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "    for key, value in token_counts.items():\n",
    "        vec[key] = value / len(lexicon)\n",
    "    doc_vectors.append(vec)\n",
    "doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_sim(vec1, vec2):\n",
    "    \"\"\" Since our vectors are dictionaries, lets convert them to lists for easier mathing. \"\"\"\n",
    "    vec1 = [val for val in vec1.values()]\n",
    "    vec2 = [val for val in vec2.values()]\n",
    "    dot_prod = 0\n",
    "    \n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "        \n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    \n",
    "    return dot_prod / (mag_1 * mag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4445004445006667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(doc_vectors[0], doc_vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpiaenv",
   "language": "python",
   "name": "nlpiaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
