{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpia.loaders import get_data\n",
    "wv = get_data('word2vec')  # <1>\n",
    "# 100%|############################| 402111/402111 [01:02<00:00, 6455.57it/s]\n",
    "len(wv.vocab), len(wv[next(iter(wv.vocab))])\n",
    "# (3000000, 300)\n",
    "wv.vectors.shape\n",
    "# (3000000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "num_words, num_dimensions = wv.vectors.shape  # <1>\n",
    "index = AnnoyIndex(num_dimensions)\n",
    "index.set_seed(1983)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 301944/3000000 [00:09<01:29, 30260.22it/s]/home/michael/.local/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|██████████| 3000000/3000000 [01:38<00:00, 30410.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i, word in enumerate(tqdm(wv.index2word)):\n",
    "    index.add_item(i, wv[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_trees = int(np.log(num_words).round(0))  # <1>\n",
    "index.build(num_trees)  # <2>\n",
    "index.save('Word2vec_index.ann')  # <3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9494"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.vocab['Harry_Potter'].index  # <1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2990506"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.vocab['Harry_Potter'].count  # <2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2id = dict(zip(wv.vocab, range(len(wv.vocab))))  # <3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9494"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2id['Harry_Potter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9494,\n",
       " 32643,\n",
       " 407349,\n",
       " 39034,\n",
       " 14728,\n",
       " 1752224,\n",
       " 51081,\n",
       " 43101,\n",
       " 22364,\n",
       " 113955,\n",
       " 155169]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = index.get_nns_by_item(w2id['Harry_Potter'], 11)  # <4>\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry_Potter',\n",
       " 'Narnia',\n",
       " 'Harry_Potters',\n",
       " 'Sherlock_Holmes',\n",
       " 'Star_Wars',\n",
       " 'Hallows_Part',\n",
       " 'Sith',\n",
       " 'Toy_Story_3',\n",
       " 'Shrek',\n",
       " 'Sorcerer_Apprentice',\n",
       " 'LOTR']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wv.index2word[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/nlpiaenv/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['JK_Rowling_Harry_Potter',\n",
       " 'JK_Rowling',\n",
       " 'boy_wizard',\n",
       " 'Deathly_Hallows',\n",
       " 'Half_Blood_Prince',\n",
       " 'Rowling',\n",
       " 'Actor_Rupert_Grint',\n",
       " 'HARRY_Potter',\n",
       " 'wizard_Harry_Potter',\n",
       " 'HARRY_POTTER']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word, similarity in wv.most_similar('Harry_Potter', topn=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cos = AnnoyIndex(f=num_dimensions, metric='angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: </s>\n",
      "100000: distinctiveness\n",
      "200000: barbiturate\n",
      "300000: Sony_PS3\n",
      "400000: Infiniti_FX\n",
      "500000: Attorney_Bud_Cummins\n",
      "600000: Giske\n",
      "700000: f_***_er\n",
      "800000: Shaw_Stockbroking_Ltd.\n",
      "900000: HKSTP\n",
      "1000000: Starwood_Hotels_HOT\n",
      "1100000: McGrath_RentCorp_NASDAQ_MGRC\n",
      "1200000: Piveteau\n",
      "1300000: Rob_Pavey\n",
      "1400000: Giant_Octopus\n",
      "1500000: eur_UPM_Kymmene\n",
      "1600000: CSSL\n",
      "1700000: Lubina\n",
      "1800000: Ndian\n",
      "1900000: Cape_Solander\n",
      "2000000: Iordanis\n",
      "2100000: Allegiance_recitation\n",
      "2200000: brandy_soaked\n",
      "2300000: Coach_Kurt_Budke\n",
      "2400000: backcountry_hikers\n",
      "2500000: Brawn_BMW_Sauber\n",
      "2600000: cedar_juniper\n",
      "2700000: Wendy_Liberatore\n",
      "2800000: Management_GDCM\n",
      "2900000: BOARDED_UP\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(wv.index2word):\n",
    "    if not i % 100000:\n",
    "        print('{}: {}'.format(i, word))\n",
    "    index_cos.add_item(i, wv[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_cos.build(30)\n",
    "index_cos.save('Word2vec_cos_index.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9494, 71557, 41526, 340510, 337152, 420722, 148450, 852429, 2339857, 2149220]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_cos = index_cos.get_nns_by_item(w2id['Harry_Potter'], 10)\n",
    "ids_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry_Potter',\n",
       " 'boy_wizard',\n",
       " 'Half_Blood_Prince',\n",
       " 'wizard_Harry_Potter',\n",
       " 'Stephenie_Meyer_Twilight',\n",
       " 'Potter_mania',\n",
       " 'wizarding',\n",
       " 'Stephenie_Meyers',\n",
       " 'Philosophers_Stone',\n",
       " 'Fenrir_Greyback']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wv.index2word[i] for i in ids_cos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_top10 = zip([wv.index2word[i] for i in ids], [wv.index2word[i] for i in ids_cos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoy_15trees</th>\n",
       "      <th>annoy_30trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry_Potter</td>\n",
       "      <td>Harry_Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Narnia</td>\n",
       "      <td>boy_wizard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry_Potters</td>\n",
       "      <td>Half_Blood_Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sherlock_Holmes</td>\n",
       "      <td>wizard_Harry_Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star_Wars</td>\n",
       "      <td>Stephenie_Meyer_Twilight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hallows_Part</td>\n",
       "      <td>Potter_mania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sith</td>\n",
       "      <td>wizarding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Toy_Story_3</td>\n",
       "      <td>Stephenie_Meyers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shrek</td>\n",
       "      <td>Philosophers_Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sorcerer_Apprentice</td>\n",
       "      <td>Fenrir_Greyback</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         annoy_15trees             annoy_30trees\n",
       "0         Harry_Potter              Harry_Potter\n",
       "1               Narnia                boy_wizard\n",
       "2        Harry_Potters         Half_Blood_Prince\n",
       "3      Sherlock_Holmes       wizard_Harry_Potter\n",
       "4            Star_Wars  Stephenie_Meyer_Twilight\n",
       "5         Hallows_Part              Potter_mania\n",
       "6                 Sith                 wizarding\n",
       "7          Toy_Story_3          Stephenie_Meyers\n",
       "8                Shrek        Philosophers_Stone\n",
       "9  Sorcerer_Apprentice           Fenrir_Greyback"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(annoy_top10, columns=['annoy_15trees', 'annoy_30trees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2],\n",
       "       [ 3.4],\n",
       "       [ 5.6],\n",
       "       [-7.8],\n",
       "       [ 9. ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_values = np.array([-1.2, 3.4, 5.6, -7.8, 9.0]).reshape(-1, 1)\n",
    "scaler.fit(real_values)\n",
    "real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39, 66, 79, 0, 100]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(x * 100.) for x in scaler.transform(real_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpiaenv",
   "language": "python",
   "name": "nlpiaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
